import streamlit as st
import pandas as pd
import openai
from sentence_transformers import SentenceTransformer
import numpy as np
import re
import requests

# ê¹ƒí—ˆë¸Œ ì €ì¥ì†Œ ì •ë³´
owner = "junslee96"
repo = "Bang_boardgame_chatbot"
file_path = "prompt_data"

# ë£°ë¶ íŒŒì¼ë“¤ ì½ê¸°
rulebook_contents = []
for i in range(1, 12):  # 1ë¶€í„° 11ê¹Œì§€
    url = f"https://github.com/{owner}/{repo}/tree/main/{file_path}/ë±…!_ë£°ë¶_{i}.txt"
    response = requests.get(url)
    if response.status_code == 200:
        rulebook_contents.append(response.text)

# QA ë°ì´í„° ì½ê¸°
qa_data_url = f"https://github.com/{owner}/{repo}/tree/main/{file_path}/qaì¢…í•©_ìµœì¢…_modified_ìˆ˜ì •.xlsx"
response = requests.get(qa_data_url)
if response.status_code == 200:
    # ì—‘ì…€ íŒŒì¼ì„ ì½ê¸° ìœ„í•´ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with open("temp.xlsx", "wb") as file:
        file.write(response.content)
    qa_df = pd.read_excel("temp.xlsx", engine='openpyxl')
else:
    print("QA ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    qa_df = None

# ê¸°ì¡´ documents ë¦¬ìŠ¤íŠ¸ì— ë£°ë¶ê³¼ QA ë°ì´í„° ì¶”ê°€
documents = []

# ë£°ë¶ ë‚´ìš© ì¶”ê°€
documents.extend(rulebook_contents)

# QA ë°ì´í„° ì¶”ê°€
if qa_df is not None:
    for _, row in qa_df.iterrows():
        documents.append(f"ì§ˆë¬¸: {row['ì§ˆë¬¸']} ë‹µë³€: {row['ë‹µë³€']}")

# ì²­í¬ í¬ê¸° ì¡°ì • ë° ì²­í¬ ìƒì„±(í•™ìŠµ ë°ì´í„° ì˜ ì½íˆê¸°)
def chunk_text(text, chunk_size=200):
    words = text.split()
    return [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]

chunked_documents = []
for doc in documents:
    chunked_documents.extend(chunk_text(doc))
documents = chunked_documents

# ë²¡í„°í™”(ë¬¸ì¥ ì¡°ë¦¬ìˆê²Œ ì •ë¦¬)
model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')
X = model.encode(documents)

# ë²¡í„°í™”ëœ ë°ì´í„°ì˜ ì°¨ì› í™•ì¸ (ë””ë²„ê¹…ìš©)
print(f"X shape: {X.shape}")

# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜ ê°œì„ (ì§ˆë¬¸ ë¬¸ì„œ 1ê°œ -> ì—¬ëŸ¬ ê°œ)
def retrieve_similar_documents(query, top_k=3):
    try:
        query_vec = model.encode([query])
        print(f"query_vec shape: {query_vec.shape}")  # ë””ë²„ê¹…ìš© ì¶œë ¥
        
        # ì°¨ì› ë¶ˆì¼ì¹˜ í•´ê²°ì„ ìœ„í•´ query_vec.T[0] ì‚¬ìš©
        similarities = np.dot(X, query_vec.T[0]).flatten()
        top_indices = similarities.argsort()[-top_k:][::-1]
        return [documents[i] for i in top_indices]
    except Exception as e:
        print(f"Error in retrieve_similar_documents: {e}")
        return []

# 'ì‚¬ëŒ'ì„ 'í”Œë ˆì´ì–´'ë¡œ ëŒ€ì²´í•˜ëŠ” í•¨ìˆ˜
def replace_terms(text):
    replace_dict = {'ì‚¬ëŒ': 'í”Œë ˆì´ì–´'}
    for key, value in replace_dict.items():
        text = re.sub(key, value, text)
    return text

# Show title and description.
st.title("ğŸ’¬ Chatbot")
st.write(
    "This is a simple chatbot that uses OpenAI's gpt-4o-mini model to generate responses. "
    "To use this app, you need to provide an OpenAI API key, which you can get [here](https://platform.openai.com/account/api-keys). "
    "You can also learn how to build this app step by step by [following our tutorial](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps)."
)

# Ask user for their OpenAI API key via `st.text_input`.
openai_api_key = st.text_input("OpenAI API Key", type="password")
if not openai_api_key:
    st.info("Please add your OpenAI API key to continue.", icon="ğŸ—ï¸")
else:
    # Create an OpenAI client.
    client = openai.OpenAI(api_key=openai_api_key)

    # Create a session state variable to store the chat messages.
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display the existing chat messages via `st.chat_message`.
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Create a chat input field to allow the user to enter a message.
    if prompt := st.chat_input("What is up?"):
        # Store and display the current prompt.
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ì§ˆë¬¸ì— 'ì‚¬ëŒ'ì„ 'í”Œë ˆì´ì–´'ë¡œ ëŒ€ì²´
        modified_question = replace_terms(prompt)

        try:
            # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
            retrieved_docs = retrieve_similar_documents(modified_question)

            # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = "\n".join(retrieved_docs)
            answer_prompt = f"ì»¨í…ìŠ¤íŠ¸: {context}\n\nì§ˆë¬¸: {modified_question}\në‹µë³€:"

            # OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "assistant", "content": answer_prompt}
                ],
                max_tokens=200,
                stream=False
            )

            # ë‹µë³€ ì €ì¥ ë° í‘œì‹œ
            answer = response.choices[0].message.content
            st.session_state.messages.append({"role": "assistant", "content": answer})
            with st.chat_message("assistant"):
                st.markdown(answer)
        
        except Exception as e:
            st.error(f"An error occurred while generating a response: {e}")
